Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Ratanamahatana2004,
author = {Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
booktitle = {Proceedings of the 2004 SIAM international conference on data mining},
pages = {11--22},
publisher = {SIAM},
title = {{Making time-series classification more accurate using learned constraints}},
year = {2004}
}
@inproceedings{Niculescu-Mizil2005,
author = {Niculescu-Mizil, Alexandru and Caruana, Rich},
booktitle = {Proceedings of the 22nd international conference on Machine learning},
file = {:Users/carinah/polybox/Mendeley/Niculescu-Mizil, Caruana/Proceedings of the 22nd international conference on Machine learning/Niculescu-Mizil, Caruana - 2005 - Predicting good probabilities with supervised learning.pdf:pdf},
pages = {625--632},
title = {{Predicting good probabilities with supervised learning}},
year = {2005}
}
@article{Bruinsma2019,
abstract = {Wordscores is a popular computational text analysis method with numerous applications in communication research. Wordscores claims to scale documents on specified dimensions without requiring researchers to read or even understand the language of the input text. We investigate whether Wordscores delivers this claim by scaling the Euromanifestos of 117 political parties across 23 countries on 4 salient dimensions of political conflict. We assess validity by comparing the Wordscores estimates to expert surveys and other judgmental measures, and by examining the Wordscores's estimates ability to predict party membership in the European Parliament groups. We find that the Wordscores estimates correlate poorly with expert and judgmental measures of party positions, while the latter outperform Wordscores in the predictive validity test. We conclude that Wordscores does not live up to its original claim of a “quick and easy” language blind method, and urge researchers to demonstrate the validity of the method in their domain of interest before any empirical analysis.},
author = {Bruinsma, Bastiaan and Gemenis, Kostas},
doi = {10.1080/19312458.2019.1594741},
file = {:Users/carinah/polybox/Mendeley/Bruinsma, Gemenis/Communication Methods and Measures/Bruinsma, Gemenis - 2019 - Validating Wordscores The Promises and Pitfalls of Computational Text Scaling.pdf:pdf},
issn = {19312466},
journal = {Communication Methods and Measures},
number = {3},
pages = {212--227},
publisher = {Routledge},
title = {{Validating Wordscores: The Promises and Pitfalls of Computational Text Scaling}},
url = {https://doi.org/10.1080/19312458.2019.1594741},
volume = {13},
year = {2019}
}
@article{Slapin2008,
abstract = {Recent advances in computational content analysis have provided scholars promising new ways for estimating party positions. However, existing text-based methods face challenges in producing valid and reliable time-series data. This article proposes a scaling algorithm called WORDFISH to estimate policy positions based on word frequencies in texts. The technique allows researchers to locate parties in one or multiple elections. We demonstrate the algorithm by estimating the positions of German political parties from 1990 to 2005 using word frequencies in party manifestos. The extracted positions reflect changes in the party system more accurately than existing time-series estimates. In addition, the method allows researchers to examine which words are important for placing parties on the left and on the right. We find that words with strong political connotations are the best discriminators between parties. Finally, a series of robustness checks demonstrate that the estimated positions are insensitive to distributional assumptions and document selection. {\textcopyright} 2008, Midwest Political Science Association.},
author = {Slapin, Jonathan B. and Proksch, Sven Oliver},
doi = {10.1111/j.1540-5907.2008.00338.x},
file = {:Users/carinah/polybox/Mendeley/Slapin, Proksch/American Journal of Political Science/Slapin, Proksch - 2008 - A scaling model for estimating time-series party positions from Texts.pdf:pdf},
issn = {00925853},
journal = {American Journal of Political Science},
number = {3},
pages = {705--722},
title = {{A scaling model for estimating time-series party positions from Texts}},
volume = {52},
year = {2008}
}
@inproceedings{Cuturi2011,
abstract = {We propose novel approaches to cast the widely-used family of Dynamic Time Warping (DTW) distances and similarities as positive definite kernels for time series. To this effect, we provide new theoretical insights on the family of Global Alignment kernels introduced by Cuturi et al. (2007) and propose alternative kernels which are both positive definite and faster to compute. We provide experimental evidence that these alternatives are both faster and more efficient in classification tasks than other kernels based on the DTW formalism. Copyright 2011 by the author(s)/owner(s).},
author = {Cuturi, Marco},
booktitle = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
file = {:Users/carinah/polybox/Mendeley/Cuturi/Proceedings of the 28th International Conference on Machine Learning, ICML 2011/Cuturi - 2011 - Fast global alignment kernels.pdf:pdf},
isbn = {9781450306195},
pages = {929--936},
title = {{Fast Global Alignment Kernels}},
year = {2011}
}
@article{Joulin2016,
author = {Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
file = {:Users/carinah/polybox/Mendeley/Joulin et al/15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017 - Proceedings of Conference/Joulin et al. - 2017 - Bag of tricks for efficient text classification.pdf:pdf},
journal = {arXiv preprint arXiv:1607.01759},
title = {{Bag of tricks for efficient text classification}},
year = {2016}
}
@book{Bird2009,
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
isbn = {0596555717},
publisher = {" O'Reilly Media, Inc."},
title = {{Natural language processing with Python: analyzing text with the natural language toolkit}},
year = {2009}
}
@unpublished{Fong2020,
abstract = {In text, images, merged surveys, voter files, and elsewhere, data sets are often missing important covariates, either because they are latent features of observations (such as sentiment in text) or because they are not collected (such as race in voter files). One promising approach for coping with this missing data is to find the true values of the covariate for a subset of the observations and then train a machine learning algorithm to predict the values of the covariate for the other observations. However, simply plugging in these predictions without regard for prediction error renders downstream regression analyses inconsistent. Even for accurate machine learning predictions, the resulting inconsistency can be as large as the effect size the analyst wants to estimate. We describe a procedure to avoid these inconsistencies that exploits the presence of hand-labeled data as a validation set. Our approach relaxes nearly all measurement error assumptions and provides a test of those that remain. We demonstrate the performance of our estimators through simulations, an analysis of income and voting in the 2016 US presidential election, and a study of hostile political dialog on the internet. We also provide software implementing our approach. Word Count: 11,857 For helpful comments and suggestions, we would like to thank},
author = {Fong, Christian and Tyler, Matthew},
booktitle = {Forthcoming in American Journal of Political Science},
file = {:Users/carinah/polybox/Mendeley/Fong, Tyler/Forthcoming in American Journal of Political Science/Fong, Tyler - 2020 - Machine Learning Predictions as Regression Covariates(2).pdf:pdf},
title = {{Machine Learning Predictions as Regression Covariates}},
year = {2020}
}
@article{Flesch1948,
author = {Flesch, Rudolph},
issn = {1939-1854},
journal = {Journal of applied psychology},
number = {3},
pages = {221},
publisher = {American Psychological Association},
title = {{A new readability yardstick.}},
volume = {32},
year = {1948}
}
@book{Schutze2008,
author = {Sch{\"{u}}tze, Hinrich and Manning, Christopher D and Raghavan, Prabhakar},
publisher = {Cambridge University Press Cambridge},
title = {{Introduction to information retrieval}},
volume = {39},
year = {2008}
}
@article{Crammer2006,
abstract = {We present a family of margin based online learning algorithms for various prediction tasks. In particular we derive and analyze algorithms for binary and multiclass categorization, regression, uniclass prediction and sequence prediction. The update steps of our different algorithms are all based on analytical solutions to simple constrained optimization problems. This unified view al-lows us to prove worst-case loss bounds for the different algorithms and for the various decision problems based on a single lemma. Our bounds on the cumulative loss of the algorithms are relative to the smallest loss that can be attained by any fixed hypothesis, and as such are applicable to both realizable and unrealizable settings. We demonstrate some of the merits of the proposed algorithms in a series of experiments with synthetic and real data sets.},
author = {Crammer, Koby and Dekel, Ofer and Keshet, Joseph and Shalev-Shwartz, Shai and Singer, Yoram},
doi = {10.1.1.9.3429},
file = {:Users/carinah/polybox/Mendeley/Crammer et al/Journal of Machine Learning Research/Crammer et al. - 2006 - Online Passive-Aggressive Algorithms.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {551--585},
title = {{Online Passive-Aggressive Algorithms}},
url = {http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf},
volume = {7},
year = {2006}
}
@article{Bolin2014,
author = {Bolin, Jocelyn H and Edwards, Julianne M and Finch, W Holmes and Cassady, Jerrell C},
issn = {1664-1078},
journal = {Frontiers in psychology},
pages = {343},
publisher = {Frontiers},
title = {{Applications of cluster analysis to the creation of perfectionism profiles: a comparison of two clustering approaches}},
volume = {5},
year = {2014}
}
@article{Mikolov2013b,
abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
archivePrefix = {arXiv},
arxivId = {1301.3781},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
eprint = {1301.3781},
file = {:Users/carinah/polybox/Mendeley/Mikolov et al/1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings/Mikolov et al. - 2013 - Efficient estimation of word representations in vector space.pdf:pdf},
journal = {1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings},
title = {{Efficient estimation of word representations in vector space}},
year = {2013}
}
@article{Spirling2016,
author = {Spirling, Arthur},
file = {:Users/carinah/polybox/Mendeley/Spirling/The Journal of Politics/Spirling - 2016 - Democratization and linguistic complexity The effect of franchise extension on parliamentary discourse, 1832–1915.pdf:pdf},
issn = {0022-3816},
journal = {The Journal of Politics},
number = {1},
pages = {120--136},
publisher = {University of Chicago Press Chicago, IL},
title = {{Democratization and linguistic complexity: The effect of franchise extension on parliamentary discourse, 1832–1915}},
volume = {78},
year = {2016}
}
@article{Shi2019,
author = {Shi, Feng},
doi = {10.4135/9781526499608},
file = {:Users/carinah/polybox/Mendeley/Shi/Learn About Sentiment Analysis With Supervised Learning in Python With Data From the Economic News Article Tone Dataset (2016)/Shi - 2019 - Learn About Sentiment Analysis With Supervised Learning in Python With Data From the Economic News Article Tone Datas(2016).pdf:pdf},
journal = {Learn About Sentiment Analysis With Supervised Learning in Python With Data From the Economic News Article Tone Dataset (2016)},
number = {2016},
title = {{Learn About Sentiment Analysis With Supervised Learning in Python With Data From the Economic News Article Tone Dataset (2016)}},
year = {2019}
}
@article{Poole1985,
author = {Poole, Keith T and Rosenthal, Howard},
file = {:Users/carinah/polybox/Mendeley/Poole, Rosenthal/American journal of political science/Poole, Rosenthal - 1985 - A spatial model for legislative roll call analysis.pdf:pdf},
issn = {0092-5853},
journal = {American journal of political science},
pages = {357--384},
publisher = {JSTOR},
title = {{A spatial model for legislative roll call analysis}},
year = {1985}
}
@inproceedings{Socher2013a,
author = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
booktitle = {Proceedings of the 2013 conference on empirical methods in natural language processing},
pages = {1631--1642},
title = {{Recursive deep models for semantic compositionality over a sentiment treebank}},
year = {2013}
}
@article{Benoit2007,
author = {Benoit, Kenneth and Laver, Michael},
issn = {0261-3794},
journal = {Electoral Studies},
number = {1},
pages = {130--135},
publisher = {Elsevier BV},
title = {{Benchmarks for text analysis: A response to Budge and Pennings}},
volume = {26},
year = {2007}
}
@article{Laver2003,
author = {Laver, Michael and Benoit, Kenneth and Garry, John},
file = {:Users/carinah/polybox/Mendeley/Laver, Benoit, Garry/American political science review/Laver, Benoit, Garry - 2003 - Extracting policy positions from political texts using words as data(2).pdf:pdf},
issn = {1537-5943},
journal = {American political science review},
number = {2},
pages = {311--331},
publisher = {Cambridge University Press},
title = {{Extracting policy positions from political texts using words as data}},
volume = {97},
year = {2003}
}
@inproceedings{Hu2014,
abstract = {Semantic Matching Is Of Central Importance To Many Natural Language Tasks [2, 28]. A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them. As a step toward this goal, we propose convolutional neural network models for matching two sentences, by adapting the convolutional strategy in vision and speech. The proposed models not only nicely represent the hierarchical structures of sentences with their layer-by-layer composition and pooling, but also capture the rich matching patterns at different levels. Our models are rather generic, requiring no prior knowledge on language, and can hence be applied to matching tasks of different nature and in different languages. The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models.},
archivePrefix = {arXiv},
arxivId = {1503.03244},
author = {Hu, Baotian and Lu, Zhengdong and Li, Hang and Chen, Qingcai},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1503.03244},
issn = {10495258},
number = {January},
pages = {2042--2050},
title = {{Convolutional neural network architectures for matching natural language sentences}},
volume = {3},
year = {2014}
}
@article{Gentzkow2010,
author = {Gentzkow, Matthew and Shapiro, Jesse M},
file = {:Users/carinah/polybox/Mendeley/Gentzkow, Shapiro/Econometrica/Gentzkow, Shapiro - 2010 - What drives media slant Evidence from US daily newspapers.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {1},
pages = {35--71},
publisher = {Wiley Online Library},
title = {{What drives media slant? Evidence from US daily newspapers}},
volume = {78},
year = {2010}
}
@article{Fiorina2005,
author = {Fiorina, Morris P and Abrams, Samuel J and Pope, Jeremy C},
file = {:Users/carinah/polybox/Mendeley/Fiorina, Abrams, Pope/The myth of a polarized America/Fiorina, Abrams, Pope - 2005 - Culture war.pdf:pdf},
journal = {The myth of a polarized America},
title = {{Culture war}},
volume = {3},
year = {2005}
}
@article{Socher2011a,
author = {Socher, Richard and Huang, Eric and Pennin, Jeffrey and Manning, Christopher D and Ng, Andrew},
journal = {Advances in neural information processing systems},
title = {{Dynamic pooling and unfolding recursive autoencoders for paraphrase detection}},
volume = {24},
year = {2011}
}
@article{Roberts2019,
abstract = {This paper demonstrates how to use the R package stm for structural topic modeling. The structural topic model allows researchers to flexibly estimate a topic model that includes document-level metadata. Estimation is accomplished through a fast variational approximation. The stm package provides many useful features, including rich ways to explore topics, estimate uncertainty, and visualize quantities of interest.},
author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin},
doi = {10.18637/jss.v091.i02},
file = {:Users/carinah/polybox/Mendeley/Roberts, Stewart, Tingley/Journal of Statistical Software/Roberts, Stewart, Tingley - 2019 - Stm An R package for structural topic models.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {LDA,R,Stm,Structural topic model,Text analysis},
number = {Ii},
title = {{Stm: An R package for structural topic models}},
volume = {91},
year = {2019}
}
@techreport{Pennington2014,
abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75{\%} on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.},
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
booktitle = {EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
doi = {10.3115/v1/d14-1162},
file = {:Users/carinah/polybox/Mendeley/Pennington, Socher, Manning/EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference/Pennington, Socher, Manning - 2014 - GloVe Global vectors for word representation.pdf:pdf},
isbn = {9781937284961},
pages = {1532--1543},
title = {{GloVe: Global vectors for word representation}},
url = {http://nlp. https://nlp.stanford.edu/projects/glove/},
year = {2014}
}
@inproceedings{Socher2013,
abstract = {Knowledge bases are an important resource for question answering and other tasks but often suffer from incompleteness and lack of ability to reason over their discrete entities and relationships. In this paper we introduce an expressive neural tensor network suitable for reasoning over relationships between two entities. Previous work represented entities as either discrete atomic units or with a single entity vector representation. We show that performance can be improved when entities are represented as an average of their constituting word vectors. This allows sharing of statistical strength between, for instance, facts involving the "Sumatran tiger" and "Bengal tiger." Lastly, we demonstrate that all models improve when these word vectors are initialized with vectors learned from unsupervised large corpora. We assess the model by considering the problem of predicting additional true relations between entities given a subset of the knowledge base. Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2{\%} and 90.0{\%}, respectively.},
author = {Socher, Richard and Chen, Danqi and Manning, Christopher D. and Ng, Andrew Y.},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
pages = {926--934},
title = {{Reasoning with neural tensor networks for knowledge base completion}},
year = {2013}
}
@article{Kim2005,
author = {Kim, Minho and Ramakrishna, R S},
file = {:Users/carinah/polybox/Mendeley/Kim, Ramakrishna/Pattern Recognition Letters/Kim, Ramakrishna - 2005 - New indices for cluster validity assessment.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
number = {15},
pages = {2353--2363},
publisher = {Elsevier},
title = {{New indices for cluster validity assessment}},
volume = {26},
year = {2005}
}
@inproceedings{Le2014,
abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: They lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of- words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
archivePrefix = {arXiv},
arxivId = {1405.4053},
author = {Le, Quoc and Mikolov, Tomas},
booktitle = {31st International Conference on Machine Learning, ICML 2014},
eprint = {1405.4053},
file = {:Users/carinah/polybox/Mendeley/Le, Mikolov/31st International Conference on Machine Learning, ICML 2014/Le, Mikolov - 2014 - Distributed representations of sentences and documents.pdf:pdf},
isbn = {9781634393973},
pages = {2931--2939},
title = {{Distributed representations of sentences and documents}},
volume = {4},
year = {2014}
}
@techreport{Gentzkow2016,
author = {Gentzkow, Matthew and Shapiro, Jesse and Taddy, Matt},
file = {:Users/carinah/polybox/Mendeley/Gentzkow, Shapiro, Taddy/Unknown/Gentzkow, Shapiro, Taddy - 2016 - Measuring polarization in high-dimensional data Method and application to congressional speech.pdf:pdf},
title = {{Measuring polarization in high-dimensional data: Method and application to congressional speech}},
year = {2016}
}
@article{Evans2007,
abstract = {Political scientists in general and public law specialists in particular have only recently begun to exploit text classification using machine learning techniques to enable the reliable and detailed content analysis of political/legal documents on a large scale. This paper provides an overview and assessment of this methodology. We describe the basics of text classification, suggest applications of this technique to enhance empirical legal research (and political science more broadly), and report results of experiments designed to test the strengths and weaknesses of alternative text classification models for classifying the positions and interpreting the content of briefs submitted to the U.S. Supreme Court. We find that the Wordscores method (introduced by Laver, Benoit, et. al. 2003), and various models using a Na{\"{i}}ve Bayes classifier, perform well at accurately classifying the ideological direction of amicus curiae briefs submitted in the Bakke (1978) and Bollinger (2003) affirmative action cases. We also find that automated feature selection techniques can enable the detection of disparate issue conceptualizations by opposing sides in a single case, and facilitate analysis of relative linguistic "reliance" and "dominance" over time. We conclude by discussing the implications of our results and pointing to areas where technical and infrastructural improvement are most needed.},
annote = {Maybe I should read this paper...},
author = {Evans, Michael C. and McIntosh, Wayne V. and Lin, Jimmy and Cates, Cynthia L.},
doi = {10.2139/ssrn.914126},
file = {:Users/carinah/polybox/Mendeley/Evans et al/SSRN Electronic Journal/Evans et al. - 2011 - Recounting the Courts Applying Automated Content Analysis to Enhance Empirical Legal Research.pdf:pdf},
issn = {1740-1453},
journal = {SSRN Electronic Journal},
number = {4},
pages = {1007--1039},
publisher = {Wiley Online Library},
title = {{Recounting the Courts? Applying Automated Content Analysis to Enhance Empirical Legal Research}},
volume = {4},
year = {2011}
}
@inproceedings{Lai2015,
author = {Lai, Siwei and Xu, Liheng and Liu, Kang and Zhao, Jun},
booktitle = {Twenty-ninth AAAI conference on artificial intelligence},
file = {:Users/carinah/polybox/Mendeley/Lai et al/Twenty-ninth AAAI conference on artificial intelligence/Lai et al. - 2015 - Recurrent convolutional neural networks for text classification.pdf:pdf},
title = {{Recurrent convolutional neural networks for text classification}},
year = {2015}
}
@article{Arbelaitz2013,
author = {Arbelaitz, Olatz and Gurrutxaga, Ibai and Muguerza, Javier and P{\'{e}}Rez, Jes{\'{u}}S M and Perona, I{\~{n}}Igo},
file = {:Users/carinah/polybox/Mendeley/Arbelaitz et al/Pattern Recognition/Arbelaitz et al. - 2013 - An extensive comparative study of cluster validity indices.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
number = {1},
pages = {243--256},
publisher = {Elsevier},
title = {{An extensive comparative study of cluster validity indices}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S003132031200338X},
volume = {46},
year = {2013}
}
@article{Spirling2016,
author = {Spirling, Arthur},
file = {:Users/carinah/polybox/Mendeley/Spirling/The Journal of Politics/Spirling - 2016 - Democratization and linguistic complexity The effect of franchise extension on parliamentary discourse, 1832–1915(2).pdf:pdf},
issn = {0022-3816},
journal = {The Journal of Politics},
number = {1},
pages = {120--136},
publisher = {University of Chicago Press Chicago, IL},
title = {{Democratization and linguistic complexity: The effect of franchise extension on parliamentary discourse, 1832–1915}},
volume = {78},
year = {2016}
}
@book{Geron2019,
author = {G{\'{e}}ron, Aur{\'{e}}lien},
isbn = {1492032611},
publisher = {O'Reilly Media},
title = {{Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems}},
year = {2019}
}
@article{Ash2017,
author = {Ash, Elliott and Morelli, Massimo and {Van Weelden}, Richard},
file = {:Users/carinah/polybox/Mendeley/Ash, Morelli, Van Weelden/The Journal of Politics/Ash, Morelli, Van Weelden - 2017 - Elections and divisiveness Theory and evidence.pdf:pdf;:Users/carinah/polybox/Mendeley/Ash, Morelli, Van Weelden/The Journal of Politics/Ash, Morelli, Van Weelden - 2017 - Elections and divisiveness Theory and evidence(3).pdf:pdf},
issn = {0022-3816},
journal = {The Journal of Politics},
number = {4},
pages = {1268--1285},
publisher = {University of Chicago Press Chicago, IL},
title = {{Elections and divisiveness: Theory and evidence}},
volume = {79},
year = {2017}
}
@inproceedings{VonLuxburg2012,
author = {{Von Luxburg}, Ulrike and Williamson, Robert C and Guyon, Isabelle},
booktitle = {Proceedings of ICML workshop on unsupervised and transfer learning},
file = {:Users/carinah/polybox/Mendeley/Kim, Ramakrishna/Pattern Recognition Letters/Kim, Ramakrishna - 2005 - New indices for cluster validity assessment.pdf:pdf},
pages = {65--79},
publisher = {JMLR Workshop and Conference Proceedings},
title = {{Clustering: Science or art?}},
year = {2012}
}
@misc{Banea2014,
abstract = {This article presents our team's participating system at SemEval-2014 Task 3. Using a meta-learning framework, we experiment with traditional knowledge-based metrics, as well as novel corpus-based measures based on deep learning paradigms, paired with varying degrees of context expansion. The framework enabled us to reach the highest overall performance among all competing systems.},
author = {Banea, Carmen and Chen, Di and Mihalcea, Rada and Cardie, Claire and Wiebe, Janyce},
doi = {10.3115/v1/s14-2098},
pages = {560--565},
publisher = {Citeseer},
title = {{SimCompass: Using Deep Learning Word Embeddings to Assess Cross-level Similarity}},
year = {2015}
}
@inproceedings{Socher2011b,
author = {Socher, Richard and Pennington, Jeffrey and Huang, Eric H and Ng, Andrew Y and Manning, Christopher D},
booktitle = {Proceedings of the 2011 conference on empirical methods in natural language processing},
pages = {151--161},
title = {{Semi-supervised recursive autoencoders for predicting sentiment distributions}},
year = {2011}
}
@article{Straube2014,
author = {Straube, Sirko and Krell, Mario M},
file = {:Users/carinah/polybox/Mendeley/Straube, Krell/Frontiers in computational neuroscience/Straube, Krell - 2014 - How to evaluate an agent's behavior to infrequent events—reliable performance estimation insensitive to class.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
pages = {43},
publisher = {Frontiers},
title = {{How to evaluate an agent's behavior to infrequent events?—reliable performance estimation insensitive to class distribution}},
volume = {8},
year = {2014}
}
@misc{Alhenak2019,
author = {Alhenak, Lubna and Hosny, Manar},
publisher = {King Saud University},
title = {{Genetic-frog-leaping algorithm for text document clustering}},
year = {2019}
}
@article{Cuturi2017,
author = {Cuturi, Marco and Blondel, Mathieu},
file = {:Users/carinah/polybox/Mendeley/Cuturi, Blondel/arXiv preprint arXiv1703.01541/Cuturi, Blondel - 2017 - Soft-DTW a differentiable loss function for time-series.pdf:pdf},
journal = {arXiv preprint arXiv:1703.01541},
title = {{Soft-DTW: a differentiable loss function for time-series}},
year = {2017}
}
@article{Sarda-Espinosa2017,
author = {Sard{\'{a}}-Espinosa, Alexis},
file = {:Users/carinah/polybox/Mendeley/Sard{\'{a}}-Espinosa/R package vignette/Sard{\'{a}}-Espinosa - 2017 - Comparing time-series clustering algorithms in r using the dtwclust package.pdf:pdf},
journal = {R package vignette},
pages = {41},
title = {{Comparing time-series clustering algorithms in r using the dtwclust package}},
volume = {12},
year = {2017}
}
@misc{Jurafsky2018,
author = {Jurafsky, Daniel and Martin, James H.},
file = {:Users/carinah/polybox/Mendeley/Jurafsky, Martin/Unknown/Jurafsky, Martin - 2018 - Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and.pdf:pdf},
title = {{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}},
year = {2018}
}
@article{Rousseeuw1987,
author = {Rousseeuw, Peter J},
issn = {0377-0427},
journal = {Journal of computational and applied mathematics},
pages = {53--65},
publisher = {Elsevier},
title = {{Silhouettes: a graphical aid to the interpretation and validation of cluster analysis}},
volume = {20},
year = {1987}
}
@article{Lauderdale2016,
abstract = {Existing approaches to measuring political disagreement from text data perform poorly except when applied to narrowly selected texts discussing the same issues and written in the same style. We demonstrate the first viable approach for estimating legislator-specific scores from the entire speech corpus of a legislature, while also producing extensive information about the evolution of speech polarization and politically loaded language. In the Irish D{\'{a}}il, we show that the dominant dimension of speech variation is government-opposition, with ministers more extreme on this dimension than backbenchers, and a second dimension distinguishing between the establishment and anti-establishment opposition parties. In the U.S. Senate, we estimate a dimension that has moderate within-party correlations with scales based on roll-call votes and campaign donation patterns; however, we observe greater overlap across parties in speech positions than roll-call positions and partisan polarization in speeches varies more clearly in response to major political events.},
author = {Lauderdale, Benjamin E and Herzog, Alexander},
doi = {10.1093/pan/mpw017},
file = {:Users/carinah/polybox/Mendeley/Lauderdale, Herzog/Political Analysis/Lauderdale, Herzog - 2016 - Measuring Political Positions from Legislative Speech(2).pdf:pdf},
issn = {14764989},
journal = {Political Analysis},
number = {3},
pages = {374--394},
title = {{Measuring Political Positions from Legislative Speech}},
volume = {24},
year = {2016}
}
@inproceedings{Kenter2015,
abstract = {Determining semantic similarity between texts is important in many tasks in information retrieval such as search, query suggestion, automatic summarization and image finding. Many approaches have been suggested, based on lexical matching, handcrafted patterns, syntactic parse trees, external sources of structured semantic knowledge and distributional semantics. However, lexical features, like string matching, do not capture semantic similarity beyond a trivial level. Furthermore, handcrafted patterns and external sources of structured semantic knowledge cannot be assumed to be available in all circumstances and for all domains. Lastly, approaches depending on parse trees are restricted to syntactically well-formed texts, typically of one sentence in length. We investigate whether determining short text similarity is possible using only semantic features-where by semantic we mean, pertaining to a representation of meaning-rather than relying on similarity in lexical or syntactic representations. We use word embeddings, vector representations of terms, computed from unla-belled data, that represent terms in a semantic space in which proximity of vectors can be interpreted as semantic similarity. We propose to go from word-level to text-level semantics by combining insights from methods based on external sources of semantic knowledge with word embeddings. A novel feature of our approach is that an arbitrary number of word embedding sets can be incorporated. We derive multiple types of meta-features from the comparison of the word vectors for short text pairs, and from the vector means of their respective word embeddings. The features representing labelled short text pairs are used to train a supervised learning algorithm. We use the trained model at testing time to predict the semantic similarity of new, unlabelled pairs of short texts. We show on a publicly available evaluation set commonly used for the task of semantic similarity that our method outperforms baseline methods that work under the same conditions.},
author = {Kenter, Tom and {De Rijke}, Maarten},
booktitle = {International Conference on Information and Knowledge Management, Proceedings},
doi = {10.1145/2806416.2806475},
file = {:Users/carinah/polybox/Mendeley/Kenter, De Rijke/International Conference on Information and Knowledge Management, Proceedings/Kenter, De Rijke - 2015 - Short text similarity with word embeddings.pdf:pdf},
isbn = {9781450337946},
keywords = {Short text similarity,Word embeddings},
pages = {1411--1420},
title = {{Short text similarity with word embeddings}},
volume = {19-23-Oct-},
year = {2015}
}
@article{Jensen2012,
author = {Jensen, Jacob and Naidu, Suresh and Kaplan, Ethan and Wilse-Samson, Laurence and Gergen, David and Zuckerman, Michael and Spirling, Arthur},
issn = {0007-2303},
journal = {Brookings Papers on Economic Activity},
pages = {1--81},
publisher = {JSTOR},
title = {{Political polarization and the dynamics of political language: Evidence from 130 years of partisan speech [with comments and discussion]}},
year = {2012}
}
@article{Hausladen2020a,
author = {Hausladen, Carina I and Schubert, Marcel H and Ash, Elliott},
issn = {0144-8188},
journal = {International Review of Law and Economics},
pages = {105903},
publisher = {Elsevier},
title = {{Text classification of ideological direction in judicial opinions}},
volume = {62},
year = {2020}
}
